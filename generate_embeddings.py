"""
‡∏Å‡∏≤‡∏£‡∏™‡∏£‡πâ‡∏≤‡∏á Embeddings ‡∏î‡πâ‡∏ß‡∏¢ Models ‡∏ó‡∏µ‡πà‡∏ó‡∏±‡∏ô‡∏™‡∏°‡∏±‡∏¢‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î
‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ß‡∏¥‡∏ä‡∏≤ Neural Network & Deep Learning

Models ‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ:
1. all-mpnet-base-v2 - ‡∏Ñ‡∏∏‡∏ì‡∏†‡∏≤‡∏û‡∏î‡∏µ‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î (768 ‡∏°‡∏¥‡∏ï‡∏¥, ‡∏ä‡πâ‡∏≤‡∏Å‡∏ß‡πà‡∏≤)
2. paraphrase-multilingual-mpnet-base-v2 - ‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö‡∏´‡∏•‡∏≤‡∏¢‡∏†‡∏≤‡∏©‡∏≤ (768 ‡∏°‡∏¥‡∏ï‡∏¥)
3. all-MiniLM-L6-v2 - ‡πÄ‡∏£‡πá‡∏ß‡∏û‡∏∑‡πâ‡∏ô‡∏ê‡∏≤‡∏ô (384 ‡∏°‡∏¥‡∏ï‡∏¥)

‡∏ü‡∏µ‡πÄ‡∏à‡∏≠‡∏£‡πå:
- ‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡πÅ‡∏ö‡∏ö batch ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏õ‡∏£‡∏∞‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡∏†‡∏≤‡∏û
- ‡πÄ‡∏£‡πà‡∏á‡∏î‡πâ‡∏ß‡∏¢ GPU (‡∏ñ‡πâ‡∏≤‡∏°‡∏µ)
- ‡∏ï‡∏¥‡∏î‡∏ï‡∏≤‡∏°‡∏Ñ‡∏ß‡∏≤‡∏°‡∏Ñ‡∏∑‡∏ö‡∏´‡∏ô‡πâ‡∏≤
- ‡∏õ‡∏£‡∏±‡∏ö‡πÅ‡∏ï‡πà‡∏á‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ memory
"""

import pandas as pd
import numpy as np
from sentence_transformers import SentenceTransformer
from tqdm import tqdm
import torch
import warnings
warnings.filterwarnings('ignore')

def generate_advanced_embeddings(
    model_name='BAAI/bge-base-en-v1.5',
    batch_size=32,
    use_gpu=False
):
    """
    ‡∏™‡∏£‡πâ‡∏≤‡∏á embeddings ‡∏Ñ‡∏∏‡∏ì‡∏†‡∏≤‡∏û‡∏™‡∏π‡∏á‡∏î‡πâ‡∏ß‡∏¢ models ‡∏ó‡∏µ‡πà‡∏ó‡∏±‡∏ô‡∏™‡∏°‡∏±‡∏¢‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î
    
    ‡∏û‡∏≤‡∏£‡∏≤‡∏°‡∏¥‡πÄ‡∏ï‡∏≠‡∏£‡πå:
        model_name: Model ‡∏ó‡∏µ‡πà‡∏à‡∏∞‡πÉ‡∏ä‡πâ
            - 'all-mpnet-base-v2': ‡∏Ñ‡∏∏‡∏ì‡∏†‡∏≤‡∏û‡∏î‡∏µ‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î (768 ‡∏°‡∏¥‡∏ï‡∏¥) ‚≠ê ‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥
            - 'paraphrase-multilingual-mpnet-base-v2': ‡∏´‡∏•‡∏≤‡∏¢‡∏†‡∏≤‡∏©‡∏≤ (768 ‡∏°‡∏¥‡∏ï‡∏¥)
            - 'all-MiniLM-L6-v2': ‡πÄ‡∏£‡πá‡∏ß (384 ‡∏°‡∏¥‡∏ï‡∏¥)
        batch_size: ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏´‡∏ô‡∏±‡∏á‡∏ó‡∏µ‡πà‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡πÉ‡∏ô‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡πÄ‡∏î‡∏µ‡∏¢‡∏ß
        use_gpu: ‡πÉ‡∏ä‡πâ GPU ‡∏ñ‡πâ‡∏≤‡∏°‡∏µ (‡πÄ‡∏£‡πá‡∏ß‡∏Å‡∏ß‡πà‡∏≤)
    
    ‡∏™‡πà‡∏á‡∏Ñ‡∏∑‡∏ô:
        numpy array ‡∏Ç‡∏≠‡∏á embeddings
    """
    
    print("="*80)
    print("üéì ‡∏Å‡∏≤‡∏£‡∏™‡∏£‡πâ‡∏≤‡∏á Embeddings ‡∏Ç‡∏±‡πâ‡∏ô‡∏™‡∏π‡∏á - Neural Network & Deep Learning")
    print("="*80)
    print()
    
    # ‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡πÅ‡∏•‡πâ‡∏ß
    print("üì• ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏´‡∏ô‡∏±‡∏á‡∏ó‡∏µ‡πà‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡πÅ‡∏•‡πâ‡∏ß...")
    movies = pd.read_pickle('data/movies.pkl')
    print(f"‚úÖ ‡πÇ‡∏´‡∏•‡∏î‡∏´‡∏ô‡∏±‡∏á {len(movies):,} ‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏á")
    
    # ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤ device
    device = 'cuda' if use_gpu and torch.cuda.is_available() else 'mps' if torch.backends.mps.is_available() else 'cpu'
    print(f"\nüñ•Ô∏è  ‡∏≠‡∏∏‡∏õ‡∏Å‡∏£‡∏ì‡πå: {device.upper()}")
    
    # ‡πÇ‡∏´‡∏•‡∏î model
    print(f"\nüß† ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡πÇ‡∏´‡∏•‡∏î Neural Network Model: {model_name}")
    print(f"   ‡∏ô‡∏µ‡πà‡∏Ñ‡∏∑‡∏≠ model ‡πÅ‡∏ö‡∏ö Transformer ‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏Å‡∏•‡πÑ‡∏Å attention")
    model = SentenceTransformer(model_name, device=device)
    
    model_info = {
        'all-mpnet-base-v2': {
            'dims': 768,
            'params': '110M',
            'quality': '‚≠ê‚≠ê‚≠ê‚≠ê ‡∏î‡∏µ‡∏°‡∏≤‡∏Å (Old Standard)',
            'speed': 'üê¢ ‡∏õ‡∏≤‡∏ô‡∏Å‡∏•‡∏≤‡∏á'
        },
        'BAAI/bge-base-en-v1.5': {
            'dims': 768,
            'params': '110M',
            'quality': '‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê ‡∏î‡∏µ‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î (New SOTA)',
            'speed': 'üöÄ ‡πÄ‡∏£‡πá‡∏ß'
        },
        'Alibaba-NLP/gte-large-en-v1.5': {
            'dims': 1024,
            'params': '434M',
            'quality': '‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê ‡πÄ‡∏ó‡∏û‡πÄ‡∏à‡πâ‡∏≤ (Best Accuracy)',
            'speed': 'üê¢üê¢ ‡∏ä‡πâ‡∏≤‡∏°‡∏≤‡∏Å'
        },
        'paraphrase-multilingual-mpnet-base-v2': {
            'dims': 768,
            'params': '278M',
            'quality': '‚≠ê‚≠ê‚≠ê‚≠ê ‡∏î‡∏µ + ‡∏´‡∏•‡∏≤‡∏¢‡∏†‡∏≤‡∏©‡∏≤',
            'speed': 'üê¢ ‡∏ä‡πâ‡∏≤‡∏Å‡∏ß‡πà‡∏≤'
        },
        'all-MiniLM-L6-v2': {
            'dims': 384,
            'params': '22M',
            'quality': '‚≠ê‚≠ê‚≠ê ‡∏î‡∏µ‡∏û‡∏≠‡πÉ‡∏ä‡πâ',
            'speed': 'üöÄüöÄ ‡πÄ‡∏£‡πá‡∏ß‡∏°‡∏≤‡∏Å'
        }
    }
    
    if model_name in model_info:
        info = model_info[model_name]
        print(f"   üìä ‡∏°‡∏¥‡∏ï‡∏¥: {info['dims']}")
        print(f"   üîß ‡∏û‡∏≤‡∏£‡∏≤‡∏°‡∏¥‡πÄ‡∏ï‡∏≠‡∏£‡πå: {info['params']}")
        print(f"   ‚ú® ‡∏Ñ‡∏∏‡∏ì‡∏†‡∏≤‡∏û: {info['quality']}")
        print(f"   ‚ö° ‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏£‡πá‡∏ß: {info['speed']}")
    
    # ‡∏™‡∏£‡πâ‡∏≤‡∏á embeddings
    print(f"\nüé¨ ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á embeddings ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏´‡∏ô‡∏±‡∏á {len(movies):,} ‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏á...")
    print(f"   ‡πÉ‡∏ä‡πâ‡∏Ñ‡∏≥‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢‡πÅ‡∏ö‡∏ö‡∏Ñ‡∏£‡∏ö‡∏ñ‡πâ‡∏ß‡∏ô‡∏ó‡∏µ‡πà‡∏°‡∏µ: ‡∏ä‡∏∑‡πà‡∏≠, ‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏á, ‡πÅ‡∏ô‡∏ß, keywords, ‡∏ô‡∏±‡∏Å‡πÅ‡∏™‡∏î‡∏á, ‡∏ú‡∏π‡πâ‡∏Å‡∏≥‡∏Å‡∏±‡∏ö")
    print(f"   ‡∏Ç‡∏ô‡∏≤‡∏î batch: {batch_size}")
    print()
    
    # ‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡πÅ‡∏ö‡∏ö batch ‡∏û‡∏£‡πâ‡∏≠‡∏° progress bar
    embeddings = []
    texts = movies['rich_description'].tolist()
    
    for i in tqdm(range(0, len(texts), batch_size), desc="‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏• batches"):
        batch = texts[i:i + batch_size]
        batch_embeddings = model.encode(
            batch,
            batch_size=batch_size,
            show_progress_bar=False,
            convert_to_numpy=True,
            normalize_embeddings=True  # L2 normalization ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏Ñ‡∏•‡πâ‡∏≤‡∏¢‡∏Ñ‡∏•‡∏∂‡∏á‡∏ó‡∏µ‡πà‡∏î‡∏µ‡∏Ç‡∏∂‡πâ‡∏ô
        )
        embeddings.append(batch_embeddings)
    
    # ‡∏£‡∏ß‡∏°‡∏ó‡∏∏‡∏Å batches
    embeddings = np.vstack(embeddings)
    
    print(f"\n‚úÖ ‡∏™‡∏£‡πâ‡∏≤‡∏á embeddings ‡πÄ‡∏™‡∏£‡πá‡∏à‡∏™‡∏°‡∏ö‡∏π‡∏£‡∏ì‡πå!")
    print(f"   ‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö: {embeddings.shape}")
    print(f"   ‡∏Ç‡∏ô‡∏≤‡∏î: {embeddings.nbytes / 1024 / 1024:.2f} MB")
    
    # ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å embeddings
    output_file = 'data/movie_embeddings.npy'
    np.save(output_file, embeddings)
    print(f"\nüíæ ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å embeddings ‡∏ó‡∏µ‡πà: {output_file}")
    
    # ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• model
    model_info_file = 'data/model_info.txt'
    with open(model_info_file, 'w') as f:
        f.write(f"Model: {model_name}\n")
        f.write(f"‡∏°‡∏¥‡∏ï‡∏¥: {embeddings.shape[1]}\n")
        f.write(f"‡∏´‡∏ô‡∏±‡∏á: {len(movies):,}\n")
        f.write(f"‡∏≠‡∏∏‡∏õ‡∏Å‡∏£‡∏ì‡πå: {device}\n")
    
    return embeddings

def compare_models():
    """
    ‡∏™‡∏£‡πâ‡∏≤‡∏á embeddings ‡∏î‡πâ‡∏ß‡∏¢‡∏ó‡∏∏‡∏Å models ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö
    (‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏∑‡∏≠‡∏Å - ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡πÄ‡∏ä‡∏¥‡∏á‡∏ß‡∏¥‡∏ä‡∏≤‡∏Å‡∏≤‡∏£)
    """
    models = [
        'all-MiniLM-L6-v2',           # ‡πÄ‡∏£‡πá‡∏ß‡∏û‡∏∑‡πâ‡∏ô‡∏ê‡∏≤‡∏ô
        'all-mpnet-base-v2',          # ‡∏Ñ‡∏∏‡∏ì‡∏†‡∏≤‡∏û‡∏î‡∏µ‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î
    ]
    
    for model_name in models:
        print(f"\n{'='*80}")
        print(f"‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏ó‡∏î‡∏™‡∏≠‡∏ö model: {model_name}")
        print(f"{'='*80}\n")
        
        embeddings = generate_advanced_embeddings(
            model_name=model_name,
            batch_size=32
        )
        
        # ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏î‡πâ‡∏ß‡∏¢‡∏ä‡∏∑‡πà‡∏≠‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏Ç‡∏≠‡∏á model
        output_file = f'data/embeddings_{model_name.replace("/", "_")}.npy'
        np.save(output_file, embeddings)
        print(f"‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏ó‡∏µ‡πà: {output_file}")

if __name__ == "__main__":
    # ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏î‡πâ‡∏ß‡∏¢ model ‡∏ó‡∏µ‡πà‡∏î‡∏µ‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î
    embeddings = generate_advanced_embeddings(
        model_name='BAAI/bge-base-en-v1.5',  # ‚≠ê New SOTA Model
        batch_size=32,
        use_gpu=False  # ‡∏ï‡∏±‡πâ‡∏á‡πÄ‡∏õ‡πá‡∏ô True ‡∏ñ‡πâ‡∏≤‡∏°‡∏µ CUDA GPU
    )
    
    print("\n" + "="*80)
    print("‚ú® ‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏£‡∏∞‡∏ö‡∏ö‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏Ç‡∏±‡πâ‡∏ô‡∏™‡∏π‡∏á!")
    print("="*80)
    print("\nüìù ‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡∏ñ‡∏±‡∏î‡πÑ‡∏õ:")
    print("   1. ‡∏£‡∏±‡∏ô: python app.py")
    print("   2. ‡∏ó‡∏î‡∏™‡∏≠‡∏ö AI ‡∏ó‡∏µ‡πà‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á‡∏î‡πâ‡∏ß‡∏¢‡∏Ñ‡∏≥‡∏Ñ‡πâ‡∏ô‡∏ó‡∏µ‡πà‡∏ã‡∏±‡∏ö‡∏ã‡πâ‡∏≠‡∏ô")
    print("   3. ‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏Å‡∏±‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏´‡∏ô‡∏±‡∏á 5,000 ‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏á‡πÄ‡∏î‡∏¥‡∏°")
